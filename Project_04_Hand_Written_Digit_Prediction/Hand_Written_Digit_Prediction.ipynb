{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1VDzOYABCWJnNPUlHAjeQB0hc77HJGQXB","authorship_tag":"ABX9TyORFDv0kuqWNo7Wg7Co5Njw"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Deep Learning Project 4 - Hand Written Digit Prediction :**\n","- ### Write a program that takes in the MNIST dataset of 28x28 pixel images and trains a machine learning model to recognize handwritten digits.\n","\n","- ### The program should be able to handle a labelled dataset of 60,000 images and use this data to train multiple machine learning models.\n","\n","- ### Your task is to compare the accuracy of different models for recognizing handwritten digits from the MNIST dataset. You can use metrics such as accuracy or F1 score to evaluate the performance of each model.\n","---\n","# **Importing necessary libraries :**\n"],"metadata":{"id":"iX7JBrC9Axg4"}},{"cell_type":"code","execution_count":39,"metadata":{"id":"7AF244fSAwaP","executionInfo":{"status":"ok","timestamp":1728939023021,"user_tz":-330,"elapsed":872,"user":{"displayName":"Anindya Chatterjee","userId":"07568261938821269796"}}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns"]},{"cell_type":"markdown","source":["## Importing the **MNIST** dataset and loading it into training and testing sets (x_train, y_train for training and x_test, y_test for testing) :"],"metadata":{"id":"sEcXjljwhiuf"}},{"cell_type":"code","source":["from keras.datasets import mnist\n","(x_train,y_train),(x_test,y_test) = mnist.load_data()"],"metadata":{"id":"pFrRVuLqhjSs","executionInfo":{"status":"ok","timestamp":1728939023867,"user_tz":-330,"elapsed":8,"user":{"displayName":"Anindya Chatterjee","userId":"07568261938821269796"}}},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":["### **x :** Represents the image data itself. Each element in 'x' is a 28 x 28 array representing the pixel values of a handwritten digit image. These are the input features for our model.\n","\n","- ### **y :** Represents the labels or the targets. Each element in 'y' is an integer between 0 and 9, corresponding to the digit that the image in 'x' represents. These are the desired output that our model should predict.\n","---\n","## Printing the shape of the x_test dataset, which represents the testing images, and will output (10000, 28, 28) :\n","- ### **10000 :** This represents the number of images in the x_test dataset. There are 10,000 images used for testing the model.\n","- ### **28 :** This represents the height (number of rows of pixels) of each image in pixels.\n","- ### **28 :** This represents the width (number of columns of pixels) of each image in pixels."],"metadata":{"id":"-2CVXBV3iG37"}},{"cell_type":"code","source":["print(x_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_XluI-_8h1I1","executionInfo":{"status":"ok","timestamp":1728939023867,"user_tz":-330,"elapsed":8,"user":{"displayName":"Anindya Chatterjee","userId":"07568261938821269796"}},"outputId":"e2656d55-f905-4403-d60d-d13d9c916240"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["(10000, 28, 28)\n"]}]},{"cell_type":"markdown","source":["## Displaying the 91st image in the training dataset **x_train** in **grayscale** using **Matplotlib** :"],"metadata":{"id":"N2Qzn8viicdQ"}},{"cell_type":"code","source":["plt.imshow(x_train[90], cmap = 'gray')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":447},"id":"3lBxQ6omiJ4U","executionInfo":{"status":"ok","timestamp":1728939025211,"user_tz":-330,"elapsed":1350,"user":{"displayName":"Anindya Chatterjee","userId":"07568261938821269796"}},"outputId":"1e666487-0f48-4147-b5b9-c9d35966b270"},"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7a325464bd90>"]},"metadata":{},"execution_count":42},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAb6UlEQVR4nO3df2xV9f3H8dctwgWhvVBKe1v5VUBhkR9mTLoG6WB0lM4QULKAGgObw4DFDFExXQRkLumGZjM4BmY/6JyCyiIwzdaJxZZsFAwoQbbZ0K5KCbTMOu6FIgXp5/sHX+52pYDncm/fbXk+kk/Se85597w5HPri3HP6uT7nnBMAAO0syboBAMD1iQACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACAiRusG/ii1tZWHT16VMnJyfL5fNbtAAA8cs7p5MmTysrKUlLS5a9zOlwAHT16VIMGDbJuAwBwjerr6zVw4MDLru9wb8ElJydbtwAAiIOr/TxPWACtXbtWQ4cOVc+ePZWTk6N33333S9XxthsAdA1X+3mekAB69dVXtXTpUq1cuVLvvfeexo0bp4KCAh0/fjwRuwMAdEYuASZMmOCKiooir8+fP++ysrJcSUnJVWtDoZCTxGAwGIxOPkKh0BV/3sf9Cujs2bPat2+f8vPzI8uSkpKUn5+vqqqqS7ZvaWlROByOGgCAri/uAfTJJ5/o/PnzysjIiFqekZGhhoaGS7YvKSlRIBCIDJ6AA4Drg/lTcMXFxQqFQpFRX19v3RIAoB3E/feA0tLS1K1bNzU2NkYtb2xsVDAYvGR7v98vv98f7zYAAB1c3K+AevToofHjx6u8vDyyrLW1VeXl5crNzY337gAAnVRCZkJYunSp5s2bp6997WuaMGGCnnvuOTU3N+u73/1uInYHAOiEEhJAc+bM0b///W+tWLFCDQ0Nuu2221RWVnbJgwkAgOuXzznnrJv4X+FwWIFAwLoNAMA1CoVCSklJuex686fgAADXJwIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYSMhs2gM4tMzPTc82OHTs81/Tu3dtzzRNPPOG5ZtOmTZ5rkHhcAQEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATDAbNtBJ+P1+zzXPPPNMTPuaOnWq55qRI0fGtC+v6uvr22U/SDyugAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJhgMlKgk/je977nuWbx4sUJ6KRtLS0tnmt27drluebQoUOea9AxcQUEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABJORAtdo9OjRnmuKi4s919x7772ea5xznmsk6fDhw55rnn32Wc81v/jFLzzXoOvgCggAYIIAAgCYiHsAPfXUU/L5fFFj1KhR8d4NAKCTS8g9oFtvvVVvv/32f3dyA7eaAADREpIMN9xwg4LBYCK+NQCgi0jIPaBDhw4pKytLw4YN03333XfFJ2paWloUDoejBgCg64t7AOXk5Ki0tFRlZWVat26d6urqNGnSJJ08ebLN7UtKShQIBCJj0KBB8W4JANABxT2ACgsL9Z3vfEdjx45VQUGB/vSnP+nEiRN67bXX2ty+uLhYoVAoMurr6+PdEgCgA0r40wF9+/bVLbfcopqamjbX+/1++f3+RLcBAOhgEv57QKdOnVJtba0yMzMTvSsAQCcS9wB67LHHVFlZqY8++ki7du3SXXfdpW7duumee+6J964AAJ1Y3N+CO3LkiO655x41NTVpwIABuuOOO7R7924NGDAg3rsCAHRiPhfrbIUJEg6HFQgErNvAdSqW31/7+9//7rmmX79+nmti+ae6cuVKzzWSVFpa6rnmyJEjMe0LXVcoFFJKSspl1zMXHADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMJ/0A6wML3v//9mOqWLVvmuSaWiUVra2s917zwwguea5599lnPNUB74QoIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCC2bDR4W3YsMFzTSwzVEtSz549Y6rzatWqVZ5rXnrppQR0AtjhCggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJJiNFuwoGg55rJk6c2C77kSS/3++55tFHH/Vcs3HjRs81QFfDFRAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATTEaKmA0YMMBzzR//+EfPNSNGjPBcE6tYJhZds2aN55rW1lbPNUBXwxUQAMAEAQQAMOE5gHbu3KkZM2YoKytLPp9PW7dujVrvnNOKFSuUmZmpXr16KT8/X4cOHYpXvwCALsJzADU3N2vcuHFau3Ztm+tXr16tNWvWaP369dqzZ4969+6tgoICnTlz5pqbBQB0HZ4fQigsLFRhYWGb65xzeu655/Tkk09q5syZkqQXX3xRGRkZ2rp1q+bOnXtt3QIAuoy43gOqq6tTQ0OD8vPzI8sCgYBycnJUVVXVZk1LS4vC4XDUAAB0fXENoIaGBklSRkZG1PKMjIzIui8qKSlRIBCIjEGDBsWzJQBAB2X+FFxxcbFCoVBk1NfXW7cEAGgHcQ2gYDAoSWpsbIxa3tjYGFn3RX6/XykpKVEDAND1xTWAsrOzFQwGVV5eHlkWDoe1Z88e5ebmxnNXAIBOzvNTcKdOnVJNTU3kdV1dnfbv36/U1FQNHjxYS5Ys0Y9//GPdfPPNys7O1vLly5WVlaVZs2bFs28AQCfnOYD27t2rKVOmRF4vXbpUkjRv3jyVlpZq2bJlam5u1oMPPqgTJ07ojjvuUFlZmXr27Bm/rgEAnZ7POeesm/hf4XBYgUDAug18CUVFRZ5rnn/++QR0cqkPP/wwprpJkyZ5rmlqaoppX0BXFwqFrnhf3/wpOADA9YkAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYMLzxzEAF02ePNlzjc/ni38jbTh48GBMdcxsfUFSkvf/m/bu3dtzzZw5czzXDBs2zHPNBx984LlGkjZt2hRTHb4croAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYYDJSKDU1Naa6UaNGea5xzsW0L6/eeuutdtlPe+rfv7/nmtzc3Jj2Fcvf7erVq2PaV3t44403YqrbvHmz55rPP/88pn1dj7gCAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYILJSKH09PSY6vr06RPnTtr2wQcfeK55/fXXE9BJ/Nx///2eax5//HHPNRkZGZ5rJCkUCnmuqa+v91wzaNAgzzWxmDJlSkx1N910k+eajz/+OKZ9XY+4AgIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCyUihZcuWxVQ3ZMiQOHfStgEDBniuSUlJiWlfn376qeeaX/3qV55r5s+f77nm888/91wzZswYzzWSVFNT47nmtttu81zz3nvvea6JxZ///OeY6phYNLG4AgIAmCCAAAAmPAfQzp07NWPGDGVlZcnn82nr1q1R6+fPny+fzxc1pk+fHq9+AQBdhOcAam5u1rhx47R27drLbjN9+nQdO3YsMjZt2nRNTQIAuh7PDyEUFhaqsLDwitv4/X4Fg8GYmwIAdH0JuQdUUVGh9PR0jRw5UosWLVJTU9Nlt21paVE4HI4aAICuL+4BNH36dL344osqLy/XT3/6U1VWVqqwsFDnz59vc/uSkhIFAoHIaK/PiAcA2Ir77wHNnTs38vWYMWM0duxYDR8+XBUVFZo6deol2xcXF2vp0qWR1+FwmBACgOtAwh/DHjZsmNLS0i77i21+v18pKSlRAwDQ9SU8gI4cOaKmpiZlZmYmelcAgE7E81twp06dirqaqaur0/79+5WamqrU1FStWrVKs2fPVjAYVG1trZYtW6YRI0aooKAgro0DADo3zwG0d+9eTZkyJfL64v2befPmad26dTpw4IB+97vf6cSJE8rKytK0adP09NNPy+/3x69rAECn5zmAJk+eLOfcZdf/5S9/uaaG0P7q6+utW7iiWH6n7Pe//31M+3rrrbc819x///2ea/7whz94rvntb3/ruSaWSUVjderUKc81//nPfzzX9OvXz3MNOibmggMAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmIj7R3Kj84l15ujly5fHuZP4mThxYrvVrV692nPN+vXrPdd89NFHnmti/RiUJ5980nPNrl27PNf861//8lwzfvx4zzW1tbWea5B4XAEBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwwWSkUH19fUx1b7/9tuea/Pz8mPbVkZWVlXmuiWVi0RtvvNFzzZ49ezzXSNKtt94aU117+PWvf+255umnn05AJ7hWXAEBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAw4XPOOesm/lc4HFYgELBuA1/ClClTPNeUl5cnoBNboVDIc80nn3ziuaZbt26ea4YOHeq5Jlaffvqp55pt27Z5rikpKfFcU1NT47kG1y4UCiklJeWy67kCAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYILJSBGz7t27e6556KGHPNcsW7bMc01mZqbnmo7O5/N5ron1n/fmzZs918Tyd9vU1OS5Bp0Hk5ECADokAggAYMJTAJWUlOj2229XcnKy0tPTNWvWLFVXV0dtc+bMGRUVFal///7q06ePZs+ercbGxrg2DQDo/DwFUGVlpYqKirR7925t375d586d07Rp09Tc3BzZ5pFHHtEbb7yhzZs3q7KyUkePHtXdd98d98YBAJ3bDV42Lisri3pdWlqq9PR07du3T3l5eQqFQvrNb36jjRs36pvf/KYkacOGDfrKV76i3bt36+tf/3r8OgcAdGrXdA/o4kcRp6amSpL27dunc+fOKT8/P7LNqFGjNHjwYFVVVbX5PVpaWhQOh6MGAKDrizmAWltbtWTJEk2cOFGjR4+WJDU0NKhHjx7q27dv1LYZGRlqaGho8/uUlJQoEAhExqBBg2JtCQDQicQcQEVFRTp48KBeeeWVa2qguLhYoVAoMurr66/p+wEAOgdP94AuWrx4sd58803t3LlTAwcOjCwPBoM6e/asTpw4EXUV1NjYqGAw2Ob38vv98vv9sbQBAOjEPF0BOee0ePFibdmyRTt27FB2dnbU+vHjx6t79+4qLy+PLKuurtbhw4eVm5sbn44BAF2CpyugoqIibdy4Udu2bVNycnLkvk4gEFCvXr0UCAT0wAMPaOnSpUpNTVVKSooefvhh5ebm8gQcACCKpwBat26dJGny5MlRyzds2KD58+dLkn7+858rKSlJs2fPVktLiwoKCvTLX/4yLs0CALoOJiNFh9erVy/PNQsWLIhpX9/61rc819x5550x7curzz//3HNNLH8eSdq1a5fnmnPnzsW0L3RdTEYKAOiQCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmmA0bAJAQzIYNAOiQCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJjwFUElJiW6//XYlJycrPT1ds2bNUnV1ddQ2kydPls/nixoLFy6Ma9MAgM7PUwBVVlaqqKhIu3fv1vbt23Xu3DlNmzZNzc3NUdstWLBAx44di4zVq1fHtWkAQOd3g5eNy8rKol6XlpYqPT1d+/btU15eXmT5jTfeqGAwGJ8OAQBd0jXdAwqFQpKk1NTUqOUvv/yy0tLSNHr0aBUXF+v06dOX/R4tLS0Kh8NRAwBwHXAxOn/+vLvzzjvdxIkTo5a/8MILrqyszB04cMC99NJL7qabbnJ33XXXZb/PypUrnSQGg8FgdLERCoWumCMxB9DChQvdkCFDXH19/RW3Ky8vd5JcTU1Nm+vPnDnjQqFQZNTX15sfNAaDwWBc+7haAHm6B3TR4sWL9eabb2rnzp0aOHDgFbfNycmRJNXU1Gj48OGXrPf7/fL7/bG0AQDoxDwFkHNODz/8sLZs2aKKigplZ2dftWb//v2SpMzMzJgaBAB0TZ4CqKioSBs3btS2bduUnJyshoYGSVIgEFCvXr1UW1urjRs36tvf/rb69++vAwcO6JFHHlFeXp7Gjh2bkD8AAKCT8nLfR5d5n2/Dhg3OOecOHz7s8vLyXGpqqvP7/W7EiBHu8ccfv+r7gP8rFAqZv2/JYDAYjGsfV/vZ7/v/YOkwwuGwAoGAdRsAgGsUCoWUkpJy2fXMBQcAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMNHhAsg5Z90CACAOrvbzvMMF0MmTJ61bAADEwdV+nvtcB7vkaG1t1dGjR5WcnCyfzxe1LhwOa9CgQaqvr1dKSopRh/Y4DhdwHC7gOFzAcbigIxwH55xOnjyprKwsJSVd/jrnhnbs6UtJSkrSwIEDr7hNSkrKdX2CXcRxuIDjcAHH4QKOwwXWxyEQCFx1mw73FhwA4PpAAAEATHSqAPL7/Vq5cqX8fr91K6Y4DhdwHC7gOFzAcbigMx2HDvcQAgDg+tCproAAAF0HAQQAMEEAAQBMEEAAABOdJoDWrl2roUOHqmfPnsrJydG7775r3VK7e+qpp+Tz+aLGqFGjrNtKuJ07d2rGjBnKysqSz+fT1q1bo9Y757RixQplZmaqV69eys/P16FDh2yaTaCrHYf58+dfcn5Mnz7dptkEKSkp0e23367k5GSlp6dr1qxZqq6ujtrmzJkzKioqUv/+/dWnTx/Nnj1bjY2NRh0nxpc5DpMnT77kfFi4cKFRx23rFAH06quvaunSpVq5cqXee+89jRs3TgUFBTp+/Lh1a+3u1ltv1bFjxyLjr3/9q3VLCdfc3Kxx48Zp7dq1ba5fvXq11qxZo/Xr12vPnj3q3bu3CgoKdObMmXbuNLGudhwkafr06VHnx6ZNm9qxw8SrrKxUUVGRdu/ere3bt+vcuXOaNm2ampubI9s88sgjeuONN7R582ZVVlbq6NGjuvvuuw27jr8vcxwkacGCBVHnw+rVq406vgzXCUyYMMEVFRVFXp8/f95lZWW5kpISw67a38qVK924ceOs2zAlyW3ZsiXyurW11QWDQffMM89Elp04ccL5/X63adMmgw7bxxePg3POzZs3z82cOdOkHyvHjx93klxlZaVz7sLffffu3d3mzZsj2/zzn/90klxVVZVVmwn3xePgnHPf+MY33A9+8AO7pr6EDn8FdPbsWe3bt0/5+fmRZUlJScrPz1dVVZVhZzYOHTqkrKwsDRs2TPfdd58OHz5s3ZKpuro6NTQ0RJ0fgUBAOTk51+X5UVFRofT0dI0cOVKLFi1SU1OTdUsJFQqFJEmpqamSpH379uncuXNR58OoUaM0ePDgLn0+fPE4XPTyyy8rLS1No0ePVnFxsU6fPm3R3mV1uMlIv+iTTz7R+fPnlZGREbU8IyNDH374oVFXNnJyclRaWqqRI0fq2LFjWrVqlSZNmqSDBw8qOTnZuj0TDQ0NktTm+XFx3fVi+vTpuvvuu5Wdna3a2lr98Ic/VGFhoaqqqtStWzfr9uKutbVVS5Ys0cSJEzV69GhJF86HHj16qG/fvlHbduXzoa3jIEn33nuvhgwZoqysLB04cEBPPPGEqqur9frrrxt2G63DBxD+q7CwMPL12LFjlZOToyFDhui1117TAw88YNgZOoK5c+dGvh4zZozGjh2r4cOHq6KiQlOnTjXsLDGKiop08ODB6+I+6JVc7jg8+OCDka/HjBmjzMxMTZ06VbW1tRo+fHh7t9mmDv8WXFpamrp163bJUyyNjY0KBoNGXXUMffv21S233KKamhrrVsxcPAc4Py41bNgwpaWldcnzY/HixXrzzTf1zjvvRH18SzAY1NmzZ3XixImo7bvq+XC549CWnJwcSepQ50OHD6AePXpo/PjxKi8vjyxrbW1VeXm5cnNzDTuzd+rUKdXW1iozM9O6FTPZ2dkKBoNR50c4HNaePXuu+/PjyJEjampq6lLnh3NOixcv1pYtW7Rjxw5lZ2dHrR8/fry6d+8edT5UV1fr8OHDXep8uNpxaMv+/fslqWOdD9ZPQXwZr7zyivP7/a60tNT94x//cA8++KDr27eva2hosG6tXT366KOuoqLC1dXVub/97W8uPz/fpaWluePHj1u3llAnT55077//vnv//fedJPezn/3Mvf/+++7jjz92zjn3k5/8xPXt29dt27bNHThwwM2cOdNlZ2e7zz77zLjz+LrScTh58qR77LHHXFVVlaurq3Nvv/22++pXv+puvvlmd+bMGevW42bRokUuEAi4iooKd+zYscg4ffp0ZJuFCxe6wYMHux07dri9e/e63Nxcl5uba9h1/F3tONTU1Lgf/ehHbu/eva6urs5t27bNDRs2zOXl5Rl3Hq1TBJBzzj3//PNu8ODBrkePHm7ChAlu9+7d1i21uzlz5rjMzEzXo0cPd9NNN7k5c+a4mpoa67YS7p133nGSLhnz5s1zzl14FHv58uUuIyPD+f1+N3XqVFddXW3bdAJc6TicPn3aTZs2zQ0YMMB1797dDRkyxC1YsKDL/SetrT+/JLdhw4bINp999pl76KGHXL9+/dyNN97o7rrrLnfs2DG7phPgasfh8OHDLi8vz6Wmpjq/3+9GjBjhHn/8cRcKhWwb/wI+jgEAYKLD3wMCAHRNBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATPwfY6vVxP4i7LgAAAAASUVORK5CYII=\n"},"metadata":{}}]},{"cell_type":"markdown","source":["# Normalizing the pixel values of the images to the range of 0 to 1 :"],"metadata":{"id":"o7949VNAj82B"}},{"cell_type":"code","source":["x_train = x_train/255.0\n","x_test = x_test/255.0"],"metadata":{"id":"_lpHcunmjQ72","executionInfo":{"status":"ok","timestamp":1728939025211,"user_tz":-330,"elapsed":25,"user":{"displayName":"Anindya Chatterjee","userId":"07568261938821269796"}}},"execution_count":43,"outputs":[]},{"cell_type":"markdown","source":["## Flattening each image in x_train and x_test into a 1D array while keeping the number of samples same :\n","---\n","- ### **'x_train.shape[0]' :** is the number of images in the training set. This ensures the same number of images are retained.\n","- ### **'-1' :** in reshape automatically calculates the remaining dimension to flatten the 2D image (28x28) into a 1D array (784).\n","- ### This is necessary for feeding data into certain machine learning models which expect a 1D input for each sample."],"metadata":{"id":"IFvDXwF8kB6q"}},{"cell_type":"code","source":["x_train = x_train.reshape(x_train.shape[0], -1)\n","x_test = x_test.reshape(x_test.shape[0], -1)"],"metadata":{"id":"_K0dNJnlkCJ_","executionInfo":{"status":"ok","timestamp":1728939025211,"user_tz":-330,"elapsed":25,"user":{"displayName":"Anindya Chatterjee","userId":"07568261938821269796"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["x_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3o58d9Wmkyrq","executionInfo":{"status":"ok","timestamp":1728939025211,"user_tz":-330,"elapsed":25,"user":{"displayName":"Anindya Chatterjee","userId":"07568261938821269796"}},"outputId":"9c54f620-2592-4ddc-a828-8503a9e52ab0"},"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000, 784)"]},"metadata":{},"execution_count":46}]},{"cell_type":"markdown","source":["## Converting class labels in **y_train** and **y_test** to one-hot encoded vectors for multi-class classification :\n","---\n","- ### **tf.keras.utils.to_categorical :** This function is used for one-hot encoding. One-hot encoding transforms categorical data (like class labels) into a numerical format suitable for machine learning models.\n","- ### **y_train, y_test :** These are the target variables representing the class labels for the training and testing datasets, respectively. In MNIST, these labels are integers ranging from 0 to 9, representing the digits.\n","- ### **10 :** This argument specifies the number of classes in the dataset. Since MNIST has 10 digits (0-9), we set it to 10.\n","## **In essence :**\n","\n","- ### The lines take the original class labels in y_train and y_test and convert them into one-hot encoded vectors. For instance, if a label is '5', it gets transformed into a vector like [0, 0, 0, 0, 0, 1, 0, 0, 0, 0], where the '1' at the 6th position represents the digit '5'."],"metadata":{"id":"NNI1yq5qzNlr"}},{"cell_type":"code","source":["y_train = tf.keras.utils.to_categorical(y_train, 10)\n","y_test = tf.keras.utils.to_categorical(y_test, 10)"],"metadata":{"id":"04GP1UEWx7lM","executionInfo":{"status":"ok","timestamp":1728939025211,"user_tz":-330,"elapsed":25,"user":{"displayName":"Anindya Chatterjee","userId":"07568261938821269796"}}},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":["## Defining a **Fully Connected Model**, also known as a **Densely Connected Model or a Multilayer Perceptron (MLP)** :\n","---\n","- ### Below code defines a sequential model using Keras and adds layers to it for a deep learning task, likely image classification :\n","- ### **model = Sequential() :** Creates a sequential model, which is a linear stack of layers.\n","- ### **model.add(Dense(units = 128, input_shape = (784, ), activation = \"relu\")) :** Adds the first layer, a dense (fully connected) layer with 128 neurons. input_shape = (784, ) specifies the input data shape, which is a 1D array of 784 elements (likely representing a flattened 28x28 image). activation = \"relu\" uses the ReLU activation function for non-linearity.\n","- ### **model.add(Dense(units = 128, activation = \"relu\")) :** Adds a second dense layer, also with 128 neurons and ReLU activation.\n","- ### **model.add(Dropout(0.25)) :** Adds a dropout layer with a rate of 0.25. Dropout helps prevent overfitting by randomly setting a fraction of input units to 0 during training.\n","- ### **model.add(Dense(units = 128, activation = \"softmax\")) :** Adds the output layer, a dense layer with 128 neurons and softmax activation. Softmax is often used in multi-class classification to produce probability distributions over the classes."],"metadata":{"id":"LCaBntm7kwAy"}},{"cell_type":"code","source":["model = Sequential() # Creates a sequential model, which is a linear stack of layers\n","model.add(Dense(units = 128, input_shape = (784, ), activation = \"relu\"))\n","model.add(Dense(units = 128, activation = \"relu\"))\n","model.add(Dropout(0.25))\n","model.add(Dense(units = 10, activation = \"softmax\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wgZiHDH5kSQf","executionInfo":{"status":"ok","timestamp":1728939025211,"user_tz":-330,"elapsed":23,"user":{"displayName":"Anindya Chatterjee","userId":"07568261938821269796"}},"outputId":"02113421-e0ef-4d85-91e1-335c2a8c2bfc"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]}]},{"cell_type":"markdown","source":["# Below code configures the model for training and displays its structure :\n","---\n","- ### **model.compile(...) :** This line is crucial for setting up the training process of our neural network. Let's understand the arguments:\n","\n","- ### **loss = \"categorical_crossentropy\" :** This specifies the loss function used to measure the difference between the model's predictions and the actual labels. Categorical cross-entropy is commonly used for multi-class classification problems like this one, where the goal is to predict one of several possible categories (digits 0-9 in this case). It calculates the loss based on the probability distribution predicted by the model and the true labels. The goal during training is to minimize this loss.\n","\n","- ### **optimizer = \"adam\" :** This defines the optimization algorithm used to update the model's weights during training to minimize the loss function. Adam (Adaptive Moment Estimation) is a popular optimization algorithm that adapts the learning rate for each weight individually, leading to faster and more stable convergence. It combines the benefits of two other optimizers, AdaGrad and RMSProp.\n","\n","- ### **metrics = [\"accuracy\"] :** This specifies the metrics used to evaluate the model's performance during and after training. In this case, accuracy is used, which measures the percentage of correctly classified samples. The model will track and report the accuracy during training, allowing us to monitor its progress.\n","\n","- ### **model.summary() :** This line prints a summary of the model's architecture, including the layers, their output shapes, and the number of parameters in each layer. This summary is helpful for understanding the model's structure and complexity.\n","\n","- ### **model.compile :** configures the training process by defining how the model learns from the data (loss function and optimizer) and how its performance is measured (metrics).\n","- ### **model.summary :** provides a concise overview of the model's structure."],"metadata":{"id":"-2xaGtG8p3kS"}},{"cell_type":"code","source":["model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":257},"id":"_Pg18BaFp30s","executionInfo":{"status":"ok","timestamp":1728939025211,"user_tz":-330,"elapsed":22,"user":{"displayName":"Anindya Chatterjee","userId":"07568261938821269796"}},"outputId":"b997732f-6d81-4047-8d8c-5426238aa340"},"execution_count":48,"outputs":[{"output_type":"display_data","data":{"text/plain":["\u001b[1mModel: \"sequential_5\"\u001b[0m\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m16,512\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n","┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n","│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n","├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n","│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n","└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Total params: \u001b[0m\u001b[38;5;34m118,282\u001b[0m (462.04 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,282</span> (462.04 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m118,282\u001b[0m (462.04 KB)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">118,282</span> (462.04 KB)\n","</pre>\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"],"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n","</pre>\n"]},"metadata":{}}]},{"cell_type":"markdown","source":["### **Total params - 133,504 (521.50 KB) :** This line indicates the total number of parameters in our model, which is 133,504. It also shows the approximate size of these parameters in memory, which is 521.50 KB. This includes all the weights and biases in all layers of our model.\n","\n","- ### **Trainable params - 133,504 (521.50 KB) :** This line specifies the number of parameters in our model that will be adjusted during the training process. In this case, all 133,504 parameters are trainable, meaning they will be updated to optimize the model's performance. It also shows the memory size of these trainable parameters.\n","\n","- ### **Non-trainable params - 0 (0.00 B) :** This line indicates the number of parameters in our model that are not trainable. These parameters are usually fixed and won't be changed during training. In our case, there are no non-trainable parameters, which is typical for simpler models. It also displays the memory size, which is 0 bytes since there are no non-trainable parameters.\n","\n","## **In essence :**\n","\n","- ### Our model has a total of 133,504 parameters, all of which are trainable and will be adjusted during the training process to improve the model's accuracy in recognizing handwritten digits. There are no fixed, non-trainable parameters in our model. The total size of these parameters in memory is approximately 521.50 KB.\n","---\n","## Below code trains the defined neural network model using training data (x_train, y_train) with a batch size of 512 and for 10 epochs :"],"metadata":{"id":"GeRajAkDsDT_"}},{"cell_type":"code","source":["model.fit(x = x_train, y = y_train, batch_size = 512, epochs = 10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bm-FI2zWqEJ8","executionInfo":{"status":"ok","timestamp":1728939046488,"user_tz":-330,"elapsed":21298,"user":{"displayName":"Anindya Chatterjee","userId":"07568261938821269796"}},"outputId":"fadb2875-de82-4583-e41c-8216ce5f1704"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - accuracy: 0.7082 - loss: 1.0141\n","Epoch 2/10\n","\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 26ms/step - accuracy: 0.9281 - loss: 0.2417\n","Epoch 3/10\n","\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9502 - loss: 0.1713\n","Epoch 4/10\n","\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.9596 - loss: 0.1346\n","Epoch 5/10\n","\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9686 - loss: 0.1069\n","Epoch 6/10\n","\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9736 - loss: 0.0905\n","Epoch 7/10\n","\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9765 - loss: 0.0773\n","Epoch 8/10\n","\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9818 - loss: 0.0639\n","Epoch 9/10\n","\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9822 - loss: 0.0581\n","Epoch 10/10\n","\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9841 - loss: 0.0517\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.history.History at 0x7a325432f0d0>"]},"metadata":{},"execution_count":49}]},{"cell_type":"markdown","source":["## Below code evaluates the trained model's performance on the test data (x_test, y_test) and returns the loss and accuracy :"],"metadata":{"id":"NGnqWHyU0KgI"}},{"cell_type":"code","source":["test_loss, test_accuracy = model.evaluate(x_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mp_EI5mc0Kyo","executionInfo":{"status":"ok","timestamp":1728939385244,"user_tz":-330,"elapsed":2682,"user":{"displayName":"Anindya Chatterjee","userId":"07568261938821269796"}},"outputId":"d6e14ccf-cee4-4a7b-e5a1-4268fb4ebcec"},"execution_count":50,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9742 - loss: 0.0842\n"]}]},{"cell_type":"markdown","source":["### Accuracy 97.42% and loss 0.0842 indicate high performance in recognizing handwritten digits."],"metadata":{"id":"C9BUpnTf1Yov"}}]}